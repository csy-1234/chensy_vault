### 一、Cursor使用
==01.为什么cursor是第一的AI  IDE？==
前言，用处

==02.背景？==
基于 VS Code 开源框架构建，是 AI 编程编辑器领域的引领者，所属公司获多轮融资，估值达 4 亿美金以上。
- 定位：支持 AI **深度集成**，功能远超普通插件，普通人也能借助它零代码开发产品。
- 收费：专业版每月 20 美金，新用户注册可免费试用 14 天。
==03.下载、安装、汉化==
下载、偏好、注册、汉化插件、打开项目
==04.核心功能==
自定义布局、tab、光标预测、chat和composer、生成代码二次校验、composer两种模式（normal、agent）
@
	@files引用文件
	@folders引用目录；（都可拖拽实现）
	@code | 选中区域+快捷键
	@docs   根据文档生成内容（自己添加文档add new doc链接，结尾/）代表递归  | 临时链接文档  @粘贴链接+add link
	@web会搜索网络内容回复
	
	


- 安装与汉化：官网下载安装包，安装后通过添加 Chinese 插件实现汉化，可导入 VS Code 配置和扩展。
- 初始设置：可选择熟悉的编辑器快捷键、设置 AI 回复语言，新手默认 VS Code 快捷键即可。
- 核心功能：包含代码自动补全与光标预测（Table 键快速应用）、Chat（问答模式）、Composer（生成 / 修改代码模式），支持近 20 个内置大模型切换。



- 辅助功能：可通过 @符号引用文件、文件夹、文档链接等，支持网络搜索（@web）、Git 提交对比（@git），还有 Notepad（上下文互通、记录笔记）、Codebase（项目代码采集与索引）功能。
- 规避 AI 乱改：让 AI 复述需求、明确指令辐射范围、拆解复杂需求、用简单逻辑引导 AI，同时可通过.cursorignore 文件忽略无需索引的文件。
- 项目协作：创建.cursor rules 文件制定项目规范，借助 Notepad 记录需求和问题，提升开发把控度。


- 免费方式：利用临时邮箱或无限邮箱，每 14 天注册新账号续期试用。
- 绕过设备检测：通过修改用户指纹的脚本或可执行文件，避免同一设备多次注册被限制，脚本支持 Windows、macOS 等系统。



- 新手先通过 Chat 模式明确需求和技术方案，再用 Composer 生成代码。
- 深度使用后建议为优质产品付费，支持工具持续优化。


==Agentic（Composer） 模型和普通模型（(Claude/GPT）区别==
Agentic 模型可以 **操作外部系统**，包括但不限于：

|类型|例子|描述|
|---|---|---|
|文件系统|创建/修改目录、文件|自动生成代码文件、移动或重命名文件|
|数据库|MySQL、PostgreSQL 等|创建表、写入数据、查询结果|
|版本控制|Git|自动 commit、push、checkout 分支|
|配置系统|Nacos、配置文件|读取或修改配置，实现自动部署或初始化|
|虚拟机/容器|Docker、VM|自动部署服务、运行脚本|
|其他工具|CLI、脚本|执行命令行操作、调用 shell 脚本|

> 也就是说，它不仅会写代码，还能 **主动执行、部署、测试**，完全可以像一个小型开发/运维助理。


### 二、git使用：

git分支策略：

单人单分支项目

多人共用单分支项目：
	适合：
		小团队
		短周期
		强实时协作
		原型验证 / 探索性开发
		CI/CD 自动化完善

分支模型：
Trunk-Based Development (TBD)
	feature flag 控制
	 trunk（main）
	 DevOps 成熟团队
GitHub Flow
	main 拉分支，PR 合并回 main
Git Flow
	区分 develop / feature / release / hotfix 分支
	发布周期长、版本管理严格的项目
	多版本维护
Forking Flow
	开源项目
	 fork 主仓库，通过 PR 贡献
```
git flow多版本管理：
Git Flow 如何支持多版本维护？

🌳 Git Flow 的分支模型回顾：
main          → 永远对应已发布版本（打 tag：v1.0, v2.0...）
develop       → 下一版本开发主线
feature/*     → 功能开发（从 develop 拉出，合并回 develop）
release/*     → 发布预演分支（从 develop 拉出，测试后合并到 main + develop）
hotfix/*      → 紧急修复分支（从 main 拉出，修复后合并到 main + develop）
✅ 关键机制：每个已发布的版本都可通过 main 上的 tag 回溯，并创建独立 hotfix

📌具体操作流程（以维护 v2.0 和 v3.0 为例）
步骤 1：已有两个发布版本
	main 上有 tag：
	v2.0（2023-01 发布）
	v3.0（2024-01 发布）
	当前 develop 在开发 v4.0
步骤 2：客户报告 v2.0 有严重安全漏洞
	注意：v3.0 和 v4.0 已重写相关模块，不能直接升级客户！
步骤 3：为 v2.0 创建专属 hotfix

	1. 基于 v2.0 的代码创建 hotfix 分支
		git checkout -b hotfix/v2.0.1 v2.0
	2. 修复漏洞（仅针对 v2.0 代码）
		# ... 编辑文件 ...
	3. 提交并打新 tag
		git commit -m "fix: security issue in auth"
		git checkout main
		git merge hotfix/v2.0.1
		git tag v2.0.1          # ← 新补丁版本
步骤 4：是否要合并到 develop？
	通常不需要！
	因为 v2.0 的代码结构和 v4.0（develop）完全不同，强行合并会引入冲突或错误。
	Git Flow 允许 hotfix 只合并到 main，不合并到 develop（实践中常跳过这步）。
✅ 结果：你成功发布了 v2.0.1，而 v3.0 和 v4.0 不受影响。
```

git四大类命令
==Start a working area==
开始一个工作区
```
git clone <url>   从远程（如 GitHub）复制整个仓库到本地

git init          在当前目录新建一个空的 Git 仓库
```
==Work on the current change==
处理当前更改
```
git add <file>  把文件加入暂存区（staging area），准备提交

git mv old new  重命名或移动文件（同时记录 Git 变更;这里是移动+暂存

git restore <file> 撤销修改
git rm <file>  从 Git 和磁盘中删除文件
 
```
==Examine history and state==
查看历史和状态
```
git log  查看提交历史

git status 查看工作区状态

git diff 比较差异

git show commit 显示提交信息

git grep "text" 代码查找关键词

git bisect 查找引入bug提交

```
==Grow, mark and tweak history==
提交历史、分支、标签
```
git branch  列出/创建/删除分支

git switch  切换分支

git commit  提交暂存区的更改到仓库

git merge   合并其他分支的更改

git rebase  把当前分支的提交“重新应用”到另一个分支上（让历史更线性）

git reset   回退到某个提交（未push）

git revert  创建一个新提交（反向提交）来“抵消”旧提交的更改

git tag     打标签（如 v1.0.0，用于发布版本）
```
==Collaborate==
#### **协作**
```
git fetch       下载远程的最新提交（但不合并）

git pull        fetch + merge，拉取并合并远程更改

git push        上传本地提交到远程仓库

```
git开发命令流程：（本地拉取+推送）
```
方案 A：直接 clone（最常用）
	实际做什么见下详解
方案 B：先创建空仓库，再添加远程（少用）
	git init <local_dir>
	it remote add origin <repo_url> #创建远程仓库别名
	git fetch origin   #全部对象的同步，不创建分支
	git checkout -b dev1 origin/dev1 #创建分支和追踪关系	


拉取同步
	git pull --rebase origin dev1 #先同步整合到本地，避免 push 失败

开发

提交commit

推送
	git push origin dev1
```

建立追踪关系：
```
1.clone 后自动追踪（默认分支）
2.fetch + checkout（非默认分支）
	克隆后本地无非默认分支：
	git checkout -b dev1 origin/dev1
3.本地创建分支，希望追踪远程分支
	git branch --set-upstream-to=origin/dev1 dev1
	或
	git branch -u origin/dev1 dev1
4.新分支首次推送
	git push -u origin dev1
```

git clone
```
1.创建本地仓库 
	在指定目录初始化一个新的 .git 本地仓库
2.克隆远程仓库所有 commit
	默认是整个 commit DAG
	包括对象（commit、tree、blob）
3.创建默认分支（或 -b <branch> ）
	本地分支与远程默认分支同名
4.建立追踪关系
	并自动建立 追踪关系：本地分支 → origin/<branch>
5.创建远程仓库别名
	默认远程仓库别名为 origin
	可以通过 git remote -v 查看
6.其他分支信息
	远程其他分支不会创建本地分支
	可通过 git branch -r 查看远程分支
	可通过 git branch -vv 查看本地分支追踪的远程分支
	
	
git clone -b <branch> <repo>
	克隆远程仓库的全部 commit（默认）
	创建本地分支
	本地分支名和 <branch> 相同
	并 自动建立追踪关系
	不会自动创建默认分支
	创建远程别名origin,通过 git remote -v 可查看
	
```



![[Pasted image 20251107163020.png]]
git commit
```
会把 暂存区（staging area/index） 的内容打包成一个新的 快照（snapshot）。

这个快照包含了项目当前的文件状态，但只包含 已经被暂存（git add）的文件，未暂存的改动不会包含在本次 commit
```
git push
```
本地仓库的 commit 推送到远程仓库

对比的是当前分支的可回溯 commit 链
对象：缺失的 commit + tree + blob 对象
不是整个仓库，不会影响其他分支或 tag

push同步失败：
远程分支有 commit，而本地没有这些 commit，Git 默认不会自动覆盖远程的历史

解决方法：
git pull --rebase
git push

总结：
push 之前保证 origin/dev1 指向的 commit
是 local/dev1 指向 commit 的祖先

git push 的行为：
	默认作用当前分支（HEAD 所指向的分支）
	必须是已建立追踪关系（upstream） 的分支
	可以直接 git pull / git push 不用写远程分支名
git push origin dev2：
	非当前分支有追踪关系，不能省略别名
完全形式：（不依赖追踪关系，可以推送到任意远程分支）
	git pull <remote> <remote-branch>:<local-branch>


```
git pull（默认merge）
```
拉取远程分支到本地

本质上只针对一个分支对比和同步

=git fetch+ git merge
merge后local/dev1一定包含远程新的提交，此时push即可

git push --rebase
把本地新commit链加到远程分支后面

git push 的默认行为：
	默认操作当前分支（HEAD 所指向的分支）
	必须是已建立追踪关系（upstream） 的分支
	可以直接 git pull / git push 不用写远程分支名
完全形式：
	git pull <remote> <remote-branch>:<local-branch>
```
### 三、frp配置


适用情况：
1.有公网云服务器（VPS）
2.内网机器想被外网访问

frp软件：
`frps` 与 `frpc`是cs架构

默认内置端口：
frp 控制端口 `7000`，dashboard `7500`，vhost http `80/8080` ， https `443/8443`

云配置：
1.frps安装在vps上，编写配文：
```
[common]
bind_addr = 0.0.0.0
bind_port = 7000               # frp 控制端口（客户端连接）
kcp_bind_port = 7001           # 可选：KCP 加速端口
vhost_http_port = 8080         # 把外网 http 请求转发到对应 client's local_port（可改成 80）
vhost_https_port = 8443        # 把外网 https 请求转发（可改成 443）
dashboard_port = 7500
dashboard_user = admin
dashboard_pwd = strongpassword123

# 安全
token = very_secret_token_here
```
2.vps安全组和防火墙放行：
登录云厂商控制台 → 找到实例 → 安全组/防火墙设置 → 新增入站规则
3.客户端配置
安装frpc，编辑配文：
```
[common]
server_addr = x.x.x.x         # VPS 公网 IP 或域名
server_port = 7000
token = very_secret_token_here

[ssh]
type = tcp
local_ip = 127.0.0.1
local_port = 22
remote_port = 6000
```


### 四、公钥私钥

公钥加密和验签（解密）
私钥解密和签名（加密）

公钥在对方手里，私钥在自己手里

发送方用自己的私钥签名、用对方的公钥加密；  
接收方用自己的私钥解密、用对方的公钥验签。


wireguard工作原理：
双方各生成一对密钥，私钥自己保留，公钥发给对方，


![[Pasted image 20251114134539.png]]


自签证书生成流程
生成私钥
	openssl genrsa -out server.key 2048
生成证书签名请求（CSR）
	openssl req -new -key server.key -out server.csr
生成自签证书
	openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt

---
命令解释
1.openssl genrsa -out server.key 2048   # 生成私钥
openssl     OpenSSL 工具
genrsa       指定加密算法rsa
-out server.key      输出文件名   
2048          密钥长度（位）
##公钥已隐含在私钥中（未单独导出）

2.openssl req -new -key server.key -out server.csr # 生成 CSR（证书签名请求）
req       处理证书请求相关操作
-new    创建新的 CSR
-key server.key   提取公钥（使用私钥）
-out server.csr    输出 CSR 文件
\## 公钥 + 身份信息 封装进 CSR

3.openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt # 生成自签证书,用 **自己的私钥** 给 CSR 中的公钥签名
x509      X.509 证书操作
-req      输入是 CSR
-days 365        证书有效期
-in server.csr     CSR 文件
-signkey server.key      用自己的私钥签名
-out server.crt             输出证书
\## 输入csr(申请者信息+公钥)、签名私钥、输出证书名

---





CA 认证证书生成流程
生成私钥
	openssl genrsa -out server.key 2048
生成证书签名请求（CSR）
	openssl req -new -key server.key -out server.csr
提交 CSR 给 CA
	提交 server.csr 给 CA（如 Let's Encrypt, DigiCert 等），CA 校验域名或公司身份
CA 返回证书
	server.crt  （签发的正式证书）
	intermediate.crt  （中间 CA）
使用证书
	配置私钥server.key,证书sever.crt,中间CA intermediate.crt

---
生成私钥（和自签一样）
	指定加密算法、输出文件名、私钥长度.key
生成 CSR（和自签一样）
	指定私钥、输出文件名.csr
提交csr
CA生成证书
	openssl x509 -req \
  -in server.csr \
  -CA ca.crt \
  -CAkey ca.key \
  -CAcreateserial \
  -out server.crt \
  -days 365 \
  -sha256
输入csr、ca证书、ca签名私钥和算法、证书有效时间
输出序列号、签名后的证书

---
对比自签和ca签：
都是一样，对 CSR 里的公钥进行签名，生成 X.509 证书
区别在于签名（的私钥，签名是否是ca的，因为）

所以说ca颁发证书指定的不是一个服务器证书，而是ullchain.pem 包含： 1️⃣ 服务器证书（你的域名） 2️⃣ 所有中间 CA 证书 根 CA 不包含，浏览器本地已有 直接在 Nginx/Apache 配置里指定即可；而自签证书里只有自签的单个证书，不是完整的信任链

完全正确，你理解得很到位 👍

我帮你整理成**条理清晰的对比表**，方便记忆：

|项目|商业 CA 签发|自签证书|
|---|---|---|
|服务器证书|是，CN=你的域名|就是自己签的证书|
|中间 CA|有，CA 会提供一条完整链（fullchain.pem）|没有，单个自签证书|
|根 CA|不包含，浏览器/操作系统本地信任|不存在，浏览器默认不信，需要手动导入|
|浏览器验证|fullchain.pem + 本地根 CA → 自动信任|浏览器找不到信任链 → 不信任，需要手动添加|
|配置方式|Nginx/Apache 直接指定 fullchain.pem + privkey.pem|Nginx/Apache 只指定自签证书 + 私钥|

---

总结一句话：

> **商业 CA 会给你“完整证书链”（fullchain.pem），你直接配置就能被浏览器信任；自签证书只有一个证书，没有链，浏览器默认不信，需要手动导入根证书。**

---



### 五、minio
概念
对象存储核心概念
	Bucket（桶）
	Object（对象）：桶中的实际数据文件，可以是图片、视频、文档等。每个对象都有唯一键（key）标识
	Alias（服务别名）：mc 中的别名，代表一个 MinIO 服务实例，包括 URL + AccessKey + SecretKey，用于操作桶和对象
权限与策略模块
	User（用户）：登录 MinIO 的账号，用 AccessKey/SecretKey 访问对象
	Policy（策略）：定义用户或匿名访问桶/对象的权限，包括 `admin`、`readwrite`、`read-only`、`download`、`read` 和自定义策略。
	Anonymous / Public Access：对未登录用户的访问策略，通过 `mc anonymous set` 设置。
服务与管理模块
	MinIO Server
	MinIO Client (mc)
	Console / WebUI
网络与接口模块
	S3 API
	HTTP / HTTPS
	Console Address
	
权限

| 策略名           | 权限描述                    | 可用操作 / 命令示例                                                                                                             |
| ------------- | ----------------------- | ----------------------------------------------------------------------------------------------------------------------- |
| **admin**     | 全权限，能管理所有桶和用户，相当于 root  | `mc mb myminio/newbucket` `mc rm -r myminio/bucket` `mc admin policy set myminio POLICY user=USER` 所有 `mc cp / ls / rm` |
| **readwrite** | 读写 bucket 内对象（上传/下载/删除） | `mc cp localfile myminio/bucket/` `mc cp myminio/bucket/object .` `mc ls myminio/bucket`                                |
| **read-only** | 只能下载和列对象                | `mc cp myminio/bucket/object .` `mc ls myminio/bucket`                                                                  |
| **download**  | 匿名下载对象，不允许列 bucket      | `curl http://IP:9000/bucket/object` `wget http://IP:9000/bucket/object` `mc cp alias/bucket/object .`（匿名访问）             |
| **read**      | 匿名读取，包括列 bucket 和下载对象   | `curl/wget` 下载对象 `mc ls alias/bucket` `mc cp alias/bucket/object .`                                                     |
| **custom**    | 用户自定义 JSON 策略，可精细控制权限   | 自定义 JSON 策略后允许的操作（上传/下载/删除/列对象等）                                                                                        |

mc客户端

```
#下载
# 下载 mc
wget https://dl.min.io/client/mc/release/linux-amd64/mc  #Linux x86_64（amd64）架构的系统通用
chmod +x mc
sudo mv mc /usr/local/bin/
```

mc客户端命令
```
# 服务别名
mc alias set myalias http://127.0.0.1:9000 minioadmin minioadmin
mc alias list
mc alias remove myalias
##所有 alias 都保存~/.mc/config.json;自带gcs、local、play、s3

# Bucket 基本操作
mc ls myalias  #列出服务下的bucket
mc ls myalias/mybucket/  #列出桶内对象也就是一样语法
mc mb myalias/mybucket
mc rb myalias/mybucket
mc rb --force myalias/mybucket
mc du myalias/mybucket

# Bucket 访问策略
mc anonymous set download myalias/mybucket==mc anonymous set read myalias/mybucket  #匿名访问策略：download 允许匿名用户下载 bucket 内的对象（只读，不可列、上传）；read允许匿名用户 读取 bucket 内容，包括列出对象和下载对象

mc anonymous set none myalias/mybucket

mc anonymous get myalias/mybucket
##json方式
创建 policy.json
mc anonymous set-json public.json myminio/mybucket

# Bucket 对象操作
上传文件
mc cp file.jpg myminio/mybucket
下载文件
mc cp myminio/mybucket/file.jpg .
curl -O http://minio-server:9000/bucket/object.jpg
wget http://minio-server:9000/bucket/object.jpg

查看 bucket 里的对象
mc ls myminio/mybucket #--recursive递归
删除对象
mc rm myminio/mybucket/file.jpg
批量删除对象
mc rm --recursive --force myminio/mybucket/folder/

# 用户
mc admin user list ALIAS（服务别名）
mc admin user info ALIAS USERNAME
mc admin user remove ALIAS USERNAME


##创建用户
mc admin user add myalias newuser newpassword
##默认管理员用户 (minioadmin) 并不会被显式注册到 MinIO 的内部用户数据库里；mc admin user list ALIAS只能看到你通过 mc admin user add 创建的新用户，不会显示默认的 minioadmin


##桶操作权限
桶操作（创建桶、删除桶、修改桶策略等）默认情况下，只有绑定了 `admin` 策略的用户，才能进行 创建桶、删除桶、设置桶策略 等操作；普通用户（绑定 `readwrite` 或 `read-only` 策略）只能访问已存在的桶内对象，不能创建或删除桶


#用户与策略绑定
mc admin policy set ALIAS POLICYNAME user=USERNAME
mc admin policy list-users ALIAS POLICYNAME
##匿名访问策略
mc anonymous set read myminio/public-bucket
mc anonymous set download myminio/public-bucket




```


网站资源访问设计
公共桶（Anonymous / Public）
	URL 可以写到 HTML、CSS、JS 文件里
	资源完全公开、能被别人直接访问或盗链
	实现简单，前端直接访问
Presigned URL（带签名的临时 URL）
	安全性高，AccessKey/SecretKey 不暴露
	请求量大时稍有性能开销
后端代理
	高安全要求的资源（医疗影像、内部文件）
	 后端承载流量，访问量大可能成为瓶颈
	实现复杂度较高
实际使用：
- **大部分网站**：公共资源用公共桶，用户资源用 Presigned URL
    
- **高度安全/企业内部**：用后端代理
    
- CDN + 公共桶 + 签名 URL 混合使用，是最常见的方案


### 六、路由器

路由器和计算机：
**路由器也是计算机，但安装了路由操作系统的计算机系统**

现代路由器（无论是硬路由还是软路由）本质上都是**专用计算机**：

- 有 CPU、内存、存储（闪存）、网络接口
- 运行操作系统（如 Linux 内核 + 路由软件）
- 执行数据包转发、NAT、DHCP、防火墙等任务

**不是所有计算机都是路由器，但——  
几乎所有现代计算机 _都具备成为路由器的潜力_。**

关键在于：**是否启用了“路由功能（### **IP 转发（IP Forwarding）**）”


网络中的角色：

 普通计算机/终端（默认行为）
- **关闭 IP 转发**（`net.ipv4.ip_forward = 0`）
- 只处理 **发给自己的 IP 包**
- 收到不是给自己的包 → 直接丢弃（不转发）
- **角色：终端主机（Host）**，不是路由器

 路由器（或配置为路由的计算机）：
- **开启 IP 转发**（`net.ipv4.ip_forward = 1`）
- 收到不是给自己的包 → 查路由表 → **转发到下一跳**
- **角色：网络中间节点（Router）**

pc变路由器的命令：
```
# 开启 IP 转发
sudo sysctl net.ipv4.ip_forward=1
# 再配上 NAT 和 DHCP，它就能替代家用路由器！
```

软硬路由：
os是否嵌入（烧录进存储）的路由器

补充

常被认为非计算机的计算机：
交换机    os：OpenWrt
智能电视   Android TV
智能手机   Android, iOS
智能手表   watchOS, Wear OS
打印机       嵌入式 Linux
nas存储     Synology DSM
摄像头       嵌入式 Linux
智能家居中枢   Linux + AI 框架
汽车主机    略
atm机        略




### 七、协议


. **协议本身是“规则”，不是软件**

- 协议（如 HTTP、TCP、IP）本质上是一份**技术规范文档**（比如 RFC 2616 是 HTTP/1.1 的官方定义）。
- 它规定了：
    - 数据格式（比如 HTTP 必须以 `GET /xxx HTTP/1.1` 开头）
    - 交互流程（比如 TCP 要三次握手）
    - 错误码含义（比如 HTTP 404 表示“没找到”）

> 📜 **协议 = 网络世界的“法律条文”**，但法律本身不会执行，需要“执法者”——也就是**实现它的软件或硬件**。


**我们接触的是“协议的实现”，而不是协议本身**

|场景|你用的软件|它实现了什么协议？|
|---|---|---|
|上网|Chrome / Safari / Edge|**HTTP/HTTPS 客户端**|
|发邮件|Outlook / Apple Mail / Gmail App|**SMTP / IMAP / POP3 客户端**|
|传文件|FileZilla / WinSCP|**FTP / SFTP 客户端**|
|打游戏|《原神》《王者荣耀》客户端|自定义应用协议（通常基于 **UDP 或 TCP**）|

> 👉 你**从未直接“使用 HTTP”**，你只是在用**实现了 HTTP 的浏览器**。


 **应用层以下的协议，普通用户几乎完全“看不见”**

- **传输层（TCP/UDP）**、**网络层（IP）**、**链路层（Wi-Fi/Ethernet）** 都由**操作系统内核**和**网卡驱动**实现。
- 你不需要知道：
    - TCP 怎么重传丢包
    - IP 包怎么被路由器转发
    - Wi-Fi 信号怎么调制

> 🔧 这些就像房子的地基、水电管道——你享受结果（能上网），但不用管怎么建的


协议的要素：

通信角色    
传输的数据单元格式
交互流程

常见协议：
![[Pasted image 20251215232113.png]]


---

✅ 一、对绝大多数开发者：**只使用协议，不实现协议**

🧑‍💻 典型场景（你每天都在做）：

- 用 `fetch()` 或 `axios` 发一个 HTTP 请求 → **你在使用 HTTP 协议**
- 用 `SMTP` 库发邮件 → **你在使用 SMTP 协议**
- 用 WebSocket 连接聊天服务器 → **你在使用 WebSocket 协议**
- 调用支付公司的 API（如微信支付）→ **你在使用基于 HTTPS 的自定义应用协议**


一般的java开发是：

使用现成的 Web 服务器（最常见）

- 你写的是 **业务逻辑代码**（比如用 Python Flask、Java Spring、Node.js Express）；
- 实际接收 HTTP 请求、解析请求行/头、管理连接的，是**底层 Web 服务器框架或反向代理**（如 Nginx、Apache、内置开发服务器）；
- 你的代码只负责：
    - 读取请求参数（如 URL、Cookie、POST 数据）
    - 执行业务（查数据库、计算）
    - 返回响应内容（HTML / JSON）

> ✅ 这种情况下：  
> **你不是在开发 Web 服务器，而是在开发“Web 应用”**，运行在 Web 服务器之上。



开发模式解析http：


八、docker

容器省的不是“运行内存”，而是：

环境隔离成本

依赖冲突成本

运维 / 部署成本

不是为了省内存而生的


**容器省的不是“运行内存”，而是：**
1.环境隔离（最大价值）- 环境隔离成本
    
- 依赖冲突成本
    
- 运维 / 部署成本

2.启停成本低（对比虚拟机
3.运维自动化友好
- docker-compose
    
- CI/CD
    
- K8s
Docker 解决的是“环境和交付问题”，不是“资源节省问题”


九、docker desktop

 docker 必须运行在 linux 内核，linux 直接安装 docker 即可；
 wsl 就是运行在 windows 的 linux 内核，所以windows运行docker层次是：
windows-wsl-docker（docker desktop/直接docker ce）


**Windows 上用 Docker Desktop + WSL2**，**内存占用确实不省，甚至偏大**

java 服务（开发态）

| 方式           | 内存                |
| ------------ | ----------------- |
| Windows 直接跑  | 300 MB ~ 1.5 GB   |
| Docker 容器跑   | **几乎一样**          |
| Docker + WSL | ==**再加 WSL 成本**== |

👉 **不开任何容器**，你看到 **1GB 左右是完全正常的**

|平台|Docker 架构|内存体验|
|---|---|---|
|**Linux**|原生 Docker|⭐⭐⭐⭐⭐|
|**Mac**|HyperKit VM|⭐⭐⭐|
|**Windows + WSL2**|Linux VM + 转换|⭐⭐|

📌 **Windows 是目前 Docker 体验最差的平台之一**


🟢 开发机（Windows）

- MySQL / Redis → **Windows 原生**
    
- Java 服务 → **IDEA 直接跑**
    
- Docker → **不用**
    

 🟢 测试 / 生产

- Linux + Docker / K8s
    

👉 **这是目前 Windows 开发最省内存、最省心的组合**



共存时的命令使用：
Windows Shell
 ├── Windows 命令（原生）
 └── wsl <Linux 命令>（转发）

Linux Shell
 ├── Linux 命令（原生）
 └── *.exe（转发到 Windows）

### 八、cerbot

动获取和更新 Let's Encrypt SSL/TLS 证书的工具，支持多种 Web 服务器（如 Apache、Nginx）和操作系统
```
安装certbot
ubuntu：
apt update  #更新库索引
apt install snapd  #ubuntu建议用snap
snap install --classic certbot  #下载snap
ln -s /snap/bin/certbot /usr/bin/certbot #创建软连接
centos/rhel:
yum install epel-release #用epel
yum install certbot
# 如果是 Nginx 用户还需安装 python3-certbot-nginx
sudo yum install python3-certbot-nginx
# Apache 用户则安装：
sudo yum install python3-certbot-apache

手动配置ssl：
方式一：web root
certbot certonly --webroot -w /var/www/html -d kjlion.com \
  --email your@email.com --agree-tos --no-eff-email
方式二：standalone
# 必须先停止 Nginx/Apache（否则 80 端口被占）
sudo systemctl stop nginx
sudo certbot certonly --standalone -d kjlion.com \
  --email your@email.com --agree-tos --no-eff-email --force-renewal
# 完成后再启动
sudo systemctl start ngin
---
参数说明：
##certbot
作用：Certbot 的主命令行工具；申请、续期、管理 Let's Encrypt 的免费 SSL/TLS 证书
##certonly
作用：只获取证书，不自动配置 Web 服务器（如 Nginx/Apache）。
说明：
默认情况下，certbot --nginx 或 certbot --apache 会自动修改配置并启用 HTTPS。
加上 certonly 表示“仅申请证书”，后续需手动配置 Web 服务器使用证书
##--webroot
作用：指定使用 Webroot 插件进行域名验证。
## -w /var/www/html
作用：指定网站的 Web 根目录（web root）。
等价于：--webroot-path /var/www/html
说明：
Certbot 会在此目录下创建 .well-known/acme-challenge/随机文件。
Let's Encrypt 的验证服务器会尝试访问：
http://kjlion.com/.well-known/acme-challenge/xxx
所以必须确保你的 Web 服务器配置允许公开访问该路径。
## -d kjlion.com
作用：指定要申请证书的 域名（Domain）。
说明：
可以多次使用 -d 添加多个域名（例如加上 www.kjlion.com）。
最终签发的是一个 多域名（SAN）证书。
所有列出的域名都必须能通过 HTTP-01 验证（即 DNS 解析到本机，且 Web 服务可响应验证请求）。
##--email your@email.com
作用：提供一个邮箱地址，用于：
注册 Let's Encrypt 账户（首次运行时）
接收证书即将过期的提醒邮件（非常重要！）
说明：
邮箱不会公开，但 Let's Encrypt 用它做账户恢复和通知。
如果不想收通知，可用 --register-unsafely-without-email（不推荐）
##--agree-tos
作用：自动同意 Let's Encrypt 的 服务条款（Terms of Service）。
说明：
首次运行 Certbot 时，会要求你交互式同意 ToS。
加上此参数后，无需人工确认，适合自动化脚本使用

##--no-eff-email
作用：不将你的邮箱共享给 EFF（Electronic Frontier Foundation），也就是不接受广告

---

自动配置ssl：
curl -O https://raw.githubusercontent.com/kejilion/sh/main/auto_cert_renewal.sh  #下载自动续签脚本：
chmod +x auto_cert_renewal.sh  #添加执行权限
定时执行
echo "0 0 * * * cd ~ && ./auto_cert_renewal.sh" I crontab -          #定时执行

certbot --nginx

测试续期是否正常：
certbot renew --dry-run
```
### 九、SSH登录
```
---
架构：C/S架构
Client	ssh	发起连接的一方
Server	sshd	监听端口、接受连接
---
下载：
SSH 的 Client 和 Server 通常来自同一个软件包（OpenSSH），  
但安装时可以只装 Client 或只装 Server

Client	openssh-client或openssh-clients	 ssh 
Server	openssh-server	                 sshd

---
方式一：（用户名密码）
配置文件：
PasswordAuthentication no
连接：
ssh user@server_ip
输入密码
优缺点：
最简单、最不安全、暴力破解---》不适合生产

方式二：（SSH 公钥登录）
配置文件：
PubkeyAuthentication yes
PasswordAuthentication no
客户端生成密钥对：
ssh-keygen
ssh-keygen -t ed25519 -C "deploy@ci-server"
拷贝公钥到客户端：
ssh-copy-id user@server  #~/.ssh/id_rsa.pub--》~/.ssh/authorized_keys
##被允许登录到当前服务器、当前用户的所有客户端公钥

连接：
ssh -i ~/.ssh/id_rsa user@server_ip
原理：非对称加密
客户端：私钥
服务端：公钥
优点：
生产主流，无需输入密码，自动化脚本常用

方式三：SSH Certificate
SSH CA 签发的用户证书
ssh -i user_key -i user-cert.pub user@server
比普通公钥 更高级一层

方式四：
公钥 + MFA
---
ssh默认登录的模式是密码登录，而且是系统的用户密码
认证方式：用户名 + 密码
密码来源：
👉 Linux 系统本地用户的密码（/etc/shadow 中的那个）
---
服务端配置文件：
/etc/ssh/sshd_config   #系统级别，无用户级别
客户端配置文件：
~/.ssh/config  #用户级别
/etc/ssh/ssh_config #全局级别
---
设置ssh登录主机别名：
服客户端配置文件
Host web-prod  #主机别名=User@hostname -p Port
    HostName 192.168.1.100   #真正要连接的服务器地址
    User deploy              #登录用户
    Port 22                  #端口
	IdentityFile ~/.ssh/id_ed25519  #指定私钥，免密登录

---
ssh禁用root登录：
PermitRootLogin no
外加
PasswordAuthentication no
AllowUsers deploy admin
用sudo用户登录
usermod -aG sudo deploy
```